{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IBM Business Automation Workflow recommendation service with IBM Business Automation Insights and Machine Learning\n",
    "\n",
    "Artificial intelligence can be combined with business processes management in many ways. For example, AI can help transforming unstructured data into data that a process can work with, through techniques such as visual or text recognition. Assistants and bots provide a better user experience and several AI services can help achieve those goals but a business process can capture lots of business data. This notebook demonstrates how to take better benefit of this data and inject machine-learning techniques to optimize processes. If for every decision that needs to be taken as part of a business process you can get a recommendation based on the decisions that have been taken in the past in similar situations, your processes are greatly enhanced.\n",
    "\n",
    "This lab uses locally deployed Openscoring - a simple Spark ML model runtime which exposes the model as a REST service. We highly recommend exploring and using **[IBM Watson Studio](https://www.ibm.com/cloud/watson-studio)** to automate your AI lifecycle management, govern and secure open source notebooks, visually prepare and build models, deploy and run models through one-click integration and manage and monitor models with explainable, trusted AI.\n",
    "\n",
    "## The recommendation service scenario\n",
    "\n",
    "The scenario here is the following: imagine an insurance company which has set up a Workflow process to approve or reject insurance claims. Some of those insurance claims are simple because, typically, the amount is small and the customer's history and claim circumstances are straightforward. Such claims can be approved automatically or, at least, follow a fast approval path. Some claims are more complex and therefore their approval path includes more steps. Let us further assume that the approval decision or the decision on which path to follow is a human task and this task is captured as a task of a Workflow process. Then it becomes interesting to consider whether a machine-learning algorithm can help figure out which decision to take, based on past decisions.\n",
    "This scenario can be adapted to any kind of human decision process. In the insurance claim example, the decision consists in approving or rejecting a claim, which amounts to a kind of yes-or-no decision. Such decisions can translate into a binary classification machine-learning problem. However, if the decision consists in dispatching a process into many other subprocesses, the scenario becomes a multiclass classification problem, which Business Automation Insights can also handle.\n",
    "\n",
    "This recommendation service uses IBM Business Automation Workflow to build the claim approval process, IBM Business Automation Insights to store the business process data, Jyputer Notebeek for building and exporting the machine-learning model and Openscoring as runtime exposing the machine-learning model as a web service. \n",
    "\n",
    "\n",
    "## Overview of the solution\n",
    "\n",
    "First, a schema outlines how all the different elements and cloud services are used together to build the expected service.\n",
    "\n",
    "![](https://raw.githubusercontent.com/radeksulc/ibm-bai-workshop/main/labs/ai/images/insurance-recommendation-architecture.png)\n",
    "\n",
    "Everything starts with the business process itself, which runs in <b>IBM Business Automation Workflow</b>. As the process is running, the business data of the process, which in our scenario contains information about the insured person and the claim, is captured by the <b>Business Automation Insight (BAI)</b> service, which stores all the process operational data and in particular our claim data in HDFS. The role of this BAI service is really to capture and store this data so that the processes can be monitored and, as the name indicates, provides you with insights on the process. BAI can render various dashboards, for example to monitor the process efficiency. In this insurance claim scenario, you are more interested in the data that is associated with activities and processes rather than in the operational data. <br>\n",
    "Once the data is captured in <b>HDFS</b>, it can be used to train a machine-learning model. After the model is trained with existing claim data and approval decisions, it should be able to provide recommendations on whether to approve or reject new claims.<br>\n",
    "The trained model needs to be deployed, which is the role of the Openscoring service. This service stores the machine-learning model and provides a scoring endpoint.\n",
    "Finally, the scoring endpoint can be invoked by the Workflow business-management process and the result transformed into a recommendation within the process user interface.\n",
    "\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "In this notebook, you will learn:\n",
    "\n",
    "- How to load time series data, in IBM Business Automation Insights, from a specific tracking point in the Workflow process\n",
    "- How to explore the format of the data and read it\n",
    "- How to create an Apache® Spark machine learning pipeline, which will be the recommendation model\n",
    "- How to train and evaluate the model.\n",
    "- Persist a pipeline and model in Openscoring repository.\n",
    "- Deploy a model for online scoring using Openscoring API.\n",
    "- Score sample scoring data by using the Openscoring API.\n",
    "- How to set up the scoring to create a recommendation service in a Workflow Coach\n",
    "\n",
    "\n",
    "## Setting up the solution\n",
    "\n",
    "To illustrate how to combine all the technologies together, the notebook comes with a business process definition.\n",
    "\n",
    "To be able to run the solution that is presented in this notebook, make sure the following elements are installed:\n",
    "\n",
    "- IBM Business Automation Workflow\n",
    "\n",
    "- IBM Business Automation Insights\n",
    "\n",
    "Business Automation Insights must be installed and connected to an HDFS data lake.\n",
    "\n",
    "- Openscoring - Already pre-installed and running on Docker.\n",
    "\n",
    "Once you have the installed the various elements, ensure you have :\n",
    "- Credentials for your Workflow instance\n",
    "- Credentials for the HDFS used by Business Automation Insights\n",
    "\n",
    "Please note the notebook requires a Python 3.5 and Spark 2.1 kernel to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking data in Business Automation Insights\n",
    "Download the latest file with .twx extension starting with 'Claim_Approval_Sample' from [labs/ai/bpm](https://github.com/radeksulc/ibm-bai-workshop/tree/main/labs/ai/bpm) and import it to you BAW instance in the [Workflow Center](https://ibmbaw:9443/WorkflowCenter/). You need to login as admin with password admin.\n",
    "\n",
    "Click on 'Process apps' pane, click on 'Import', click on 'Browse', select the downloaded twx file and click on 'OK'.\n",
    "\n",
    "In case you have the same snapshot of process application 'Claim Approval Sample' already installed, you can continue.\n",
    "\n",
    "In the Workflow Center, click 'Claim Approval Sample' process app. As you explore the process application, select 'Processes' in the left menu, you see one 'Claim approval' process, which has been defined as a single user task.\n",
    "<br>\n",
    "![](https://raw.githubusercontent.com/radeksulc/ibm-bai-workshop/main/labs/ai/images/process.png)\n",
    "<br>\n",
    "<br>\n",
    "For this process, four classes of business data have been created: claim, customer, vehicle, and recommendation. The 'claim' business data represents the data of the insurance claim. It will reference a customer and a vehicle. The 'recommendation' object will contain information from the recommendation service that's being built. This object will be examined later.<br>\n",
    "Note that this example is not intended to reflect a real claim approval system, which is notably more complex.\n",
    "The claim contains information on the vehicle: the 'make', the 'type' and 'model', and the 'year' of the vehicle, information about the customer, in particular the 'creditScore' property, which represents the customer's insurance score, and information about the claim itself such as the estimated amount, the assessment that was made, and the assessor. The example uses only some of this information. <br>\n",
    "<br>\n",
    "Since this is not a real process, we initialize the claim object with some random data.\n",
    "<br>\n",
    "![](https://raw.githubusercontent.com/radeksulc/ibm-bai-workshop/main/labs/ai/images/claimdata.png)\n",
    "<br>\n",
    "The main task in this process is to approve or reject an insurance claim and thus to decide (based on the claim data) whether to set the 'approved' attribute of the claim to 'true' or to 'false'. \n",
    "\n",
    "After the approval decision is taken --that is, when the approval task is finished-- this piece of information is stored in Business Automation Insights so that it can be fed to the machine-learning model. For this purpose, a 'tracking point' is introduced after the approval task. \n",
    "The tracking point in a process is a moment when all the current status and data is sent to Business Automation Insights. \n",
    "Each tracking point can store the appropriate data. This example stores the data of the claim that the machine algorithm is to learn from. Of course, the decision value of the 'approved' property of the claim is stored, too.\n",
    "<br>\n",
    "![](https://raw.githubusercontent.com/radeksulc/ibm-bai-workshop/main/labs/ai/images/tracking.png)\n",
    "<br>\n",
    "Each tracking point stores the information that has been specified when a tracking group has been created. The tracking group is really a model of the data that needs to be stored in BAI.<br>\n",
    "The tracking point definition specifies the tracking group and the mapping from the claim data to the tracking group data.\n",
    "<br>\n",
    "Also note the name of the tracking group: IBMBPMRSTraining_Claims, which is necessary to find the data in the next step.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data used to train the machine learning model\n",
    "At this point, it is necessary to have some data to train the machine learning model. You could continue the exercise even with few data, but you would have to run the process from Process Portal like from 10 to 20 times. Which would be time consuming. In real projects you need typically at least many thousands of records for training to get reasonable results.\n",
    "\n",
    "To make it more realistic we have prepared sample training data with 5000 records which you can use for training of the machine learning model in coming cells of this notebook.\n",
    "\n",
    "The sample data are stored in HDFS. You can open this [link to the sample data](http://namenode:50070/explorer.html#/user/bai/insurance-recommendation) in a new browser tab for review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The format of the Business Automation Insights data\n",
    "After the process has run several times, events are stored in Business Automation Insights. BAI stores many different types of events but in this scenario, the events that are registered when a tracking point is reached by a process are stored as a 'bpm-timeseries' for tracking data.\n",
    "Every time a process is going through the tracking point, a record is added to HDFS in the form of JSON data.<br>\n",
    "In this scenario, the timeseries data is partitioned by the following elements:\n",
    "- The identifier and version number of the Workflow business process application\n",
    "- The tracking group identifier \n",
    "\n",
    "Thus, HDFS file names start with the following path:<br>\n",
    "<br>\n",
    "[hdfs root]/ibm-bai/bpmn-timeseries/[processAppId]/[processAppVersionId]/tracking/[trackingGroupId]\n",
    "<br>\n",
    "<br>\n",
    "Remember, the tracking group name is IBMBPMRSTraining_Claims. To find the data, you query the various ids from the Workflow system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to find an application id and version, and the tracking group id\n",
    "\n",
    "In this example, when the process is imported into the Workflow instance, the process application IDs and versions, and the tracking group ID, do not change, Therefore, to run the example, predefined IDs could be used but the demo shows how you can retrieve all the IDs by using the IBM Workflow REST API<br>\n",
    "<br>You may skip this part and go directly to the next chapter.\n",
    "<br>You can also refer to https://www.ibm.com/support/knowledgecenter/SS8JB4_20.x/com.ibm.wbpm.ref.doc/rest/bpmrest/rest_bpm_wle.htm to get more details on the REST API that is used below.<br>\n",
    "\n",
    "Here is some Python code to set up the REST API URL and credential for the lab environment's BAW instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3, requests, json\n",
    "urllib3.disable_warnings()\n",
    "bpmrestapiurl = 'https://localhost:9443/rest/bpm/wle/v1'\n",
    "bpmusername='admin'\n",
    "bpmpassword='admin'\n",
    "\n",
    "headers = urllib3.util.make_headers(basic_auth='{username}:{password}'.format(username=bpmusername, password=bpmpassword, verify=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you retrieve the process application ID and version number by using the 'processApps' REST API. The code below searches for the 'Claim Approval Sample' application and assumes that only one version or snapshot is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process application id: 638d314f-12db-43c3-9051-89f3ce992393\n",
      "the process application version id: 2064.9ac03e85-7886-45d2-bce1-dae9822ee48b\n"
     ]
    }
   ],
   "source": [
    "url = bpmrestapiurl + '/processApps'\n",
    "response = requests.get(url, headers=headers, verify=False)\n",
    "\n",
    "[processApp] = [x for x in json.loads(response.text).get('data').get('processAppsList') if x.get('name') == 'Claim Approval Sample']\n",
    "processAppId = processApp.get('ID')\n",
    "\n",
    "# Note that the 5 first characters of the process app id below are removed\n",
    "# because the REST API returns the process application id with a 5-letter prefix that is '2066.'.\n",
    "# This prefix marks the identifier as a process application id but you won't need this prefix later.\n",
    "\n",
    "print(\"the process application id: \" + processAppId[5:])\n",
    "snapshot = processApp.get('installedSnapshots')[2]\n",
    "processAppVersionId = snapshot.get('ID')\n",
    "print(\"the process application version id: \" + processAppVersionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now retrieve the tracking group ID. For this, you call the BPM 'assets' API by using the versionId (or snapshot ID) that has just been computed. Assets are filtered so that only the definitions of the tracking group are retrieved. For this purpose, another call to the Workflow 'assets' API is necessary, using the version or snapshot identifier that has just been computed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracking group id : f1cf87ab-29ae-4b54-901a-6601b4539132\n"
     ]
    }
   ],
   "source": [
    "url = bpmrestapiurl + '/assets'\n",
    "response = requests.get(url, headers=headers, verify=False, params={'processAppId': processAppId, 'filter': 'type=TrackingGroup' })\n",
    "\n",
    "[trackingGroupId] = [x.get('poId') for x in json.loads(response.text).get('data').get('TrackingGroup') if x.get('name') == 'IBMBPMRSTraining_Claims']\n",
    "\n",
    "\n",
    "# Note that the 3 first characters of the tracking group id below are removed\n",
    "# because the REST API returns the tracking group id with a 3-letter prefix that is '14.'.\n",
    "# This prefix marks the identifier as a tracking group id but you won't need this prefix later.\n",
    "\n",
    "print('The tracking group id : ' + trackingGroupId[3:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know the processApp id and version, and the tracking group id, so that you can query data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Spark SQL to read Business Automation Insights data\n",
    "Business Automation Insights stores data in HDFS. As described above, the events coming from the Workflow instance are stored in JSON files. At this point, you must adapt the code below to specify the HDFS URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data...\n",
      "+--------------------+--------------------+--------------+------------+--------------------+-----------+--------------------+--------------------+------+--------------------+---------+-----------+-------------+--------------------+----------------------+------------------------------+---------------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+-----------------+---------------------------+----------------------+------------+-------+\n",
      "|          activityId|  activityInstanceId|  activityName|activityType|   activityVersionId|bpmCellName|         bpmSystemId|                  id|offset|            parentId|partition|performerId|performerName|processApplicationId|processApplicationName|processApplicationSnapshotName|processApplicationVersionId|   processInstanceId|sequenceId|           timestamp|       trackedFields|     trackingGroupId|   trackingGroupName|trackingGroupVersionId|     trackingPointId|trackingPointName|trackingPointOccurrenceTime|trackingPointVersionId|        type|version|\n",
      "+--------------------+--------------------+--------------+------------+--------------------+-----------+--------------------+--------------------+------+--------------------+---------+-----------+-------------+--------------------+----------------------+------------------------------+---------------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+-----------------+---------------------------+----------------------+------------+-------+\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 3168, 375...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 509, 846,...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 3216, 541...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 2472, 60,...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 1697, 966...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 3004, 170...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 3981, 701...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 3193, 261...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 1831, 567...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 109, 212,...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 1588, 140...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 2317, 505...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 3560, 339...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 341, 495,...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 482, 99, ...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 3567, 25,...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 3859, 100...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 35, 599, ...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 1603, 246...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "|bpdid:431b0753c33...|processId.bpmSyst...|Claim approval|    userTask|2064.f1659d94 - 2...|  bpmCell01|47a21c0d-7af5-4d6...| e488e5132f5f2161...|   314|processId.bpmSyst...|        0|   bpmadmin|     bpmadmin|2066.f8adcf19-53a...|  Recommendation se...|          Reco service Samp...|       2064.3a3ebfc4-da8...|processId.bpmSyst...|         6|2018-01-12T15:06:...|[false, 1122, 39,...|fb6ebad8-ddec-492...|IBMBPMRSTraining_...|  2064.f1659d94-236...|-f4ed8784d4a8bpdi...|         Tracking|       2018-01-12T15:06:...|  2064.f1659d94-236...|EVENT_THROWN|  0.1.0|\n",
      "+--------------------+--------------------+--------------+------------+--------------------+-----------+--------------------+--------------------+------+--------------------+---------+-----------+-------------+--------------------+----------------------+------------------------------+---------------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+-----------------+---------------------------+----------------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- activityId: string (nullable = true)\n",
      " |-- activityInstanceId: string (nullable = true)\n",
      " |-- activityName: string (nullable = true)\n",
      " |-- activityType: string (nullable = true)\n",
      " |-- activityVersionId: string (nullable = true)\n",
      " |-- bpmCellName: string (nullable = true)\n",
      " |-- bpmSystemId: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- parentId: string (nullable = true)\n",
      " |-- partition: long (nullable = true)\n",
      " |-- performerId: string (nullable = true)\n",
      " |-- performerName: string (nullable = true)\n",
      " |-- processApplicationId: string (nullable = true)\n",
      " |-- processApplicationName: string (nullable = true)\n",
      " |-- processApplicationSnapshotName: string (nullable = true)\n",
      " |-- processApplicationVersionId: string (nullable = true)\n",
      " |-- processInstanceId: string (nullable = true)\n",
      " |-- sequenceId: long (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- trackedFields: struct (nullable = true)\n",
      " |    |-- approved.string: string (nullable = true)\n",
      " |    |-- approvedAmount.integer: long (nullable = true)\n",
      " |    |-- creditScore.integer: long (nullable = true)\n",
      " |    |-- duration.dayTimeDuration: string (nullable = true)\n",
      " |    |-- estimateAmount.integer: long (nullable = true)\n",
      " |    |-- trackingPointOccurrenceTime.date: string (nullable = true)\n",
      " |    |-- vehicleMake.string: string (nullable = true)\n",
      " |    |-- vehicleModel.string: string (nullable = true)\n",
      " |    |-- vehicleType.string: string (nullable = true)\n",
      " |    |-- vehicleYear.integer: long (nullable = true)\n",
      " |-- trackingGroupId: string (nullable = true)\n",
      " |-- trackingGroupName: string (nullable = true)\n",
      " |-- trackingGroupVersionId: string (nullable = true)\n",
      " |-- trackingPointId: string (nullable = true)\n",
      " |-- trackingPointName: string (nullable = true)\n",
      " |-- trackingPointOccurrenceTime: string (nullable = true)\n",
      " |-- trackingPointVersionId: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data containts 4999 events\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import  SparkSession\n",
    "\n",
    "hdfs_root = 'hdfs://namenode/user/bai'\n",
    "\n",
    "processAppId = '638d314f-12db-43c3-9051-89f3ce992393'\n",
    "processAppVersionId = '2064.a731ce46-a41d-4d8f-92ae-df0782fc10b8'\n",
    "trackingGroupId = 'f1cf87ab-29ae-4b54-901a-6601b4539132'\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"dfs.client.use.datanode.hostname\", \"true\")\n",
    "\n",
    "try:\n",
    "  print(\"Getting data...\")\n",
    "\n",
    "  # Enable next line to read current real data collected by BAI\n",
    "  # timeseries = spark.read.json(hdfs_root + \"/ibm-bai/bpmn-timeseries/\" + processAppId + '/' + processAppVersionId + '/tracking/' + trackingGroupId + '/*/*')\n",
    "\n",
    "  # Or enable next line to use sample data for training of the ML model\n",
    "  timeseries = spark.read.json(hdfs_root + \"/insurance-recommendation/sample_training_data.json\")\n",
    "\n",
    "  timeseries.createOrReplaceTempView(\"timeseries\")\n",
    "  timeseries.show()\n",
    "  timeseries.printSchema()\n",
    "  print ('The data containts ' + str(timeseries.count()) + ' events')\n",
    "except Exception as e:\n",
    "  print('Exception while reading data, please ensure data was created in BAI')\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the various ids for the path are specified in the JSON path. This HDFS path could also use HDFS wildcards. Here, the * character replaces any directory or file name in the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------+-------------------+------------------------+----------------------+--------------------------------+------------------+-------------------+------------------+-------------------+\n",
      "|approved.string|approvedAmount.integer|creditScore.integer|duration.dayTimeDuration|estimateAmount.integer|trackingPointOccurrenceTime.date|vehicleMake.string|vehicleModel.string|vehicleType.string|vehicleYear.integer|\n",
      "+---------------+----------------------+-------------------+------------------------+----------------------+--------------------------------+------------------+-------------------+------------------+-------------------+\n",
      "|          false|                  3168|                375|            P13DT11H9M8S|                  3168|            2018-12-3T20:45:3...|           Peugeot|               Golf|               car|               2008|\n",
      "|          false|                   509|                846|            P13DT11H9M8S|                   559|            2018-12-3T20:45:3...|             Honda|               Golf|               car|               2009|\n",
      "|          false|                  3216|                541|            P13DT11H9M8S|                  3216|            2018-12-3T20:45:3...|              Ford|               Golf|               car|               2006|\n",
      "|          false|                  2472|                 60|            P13DT11H9M8S|                  2719|            2018-12-3T20:45:3...|           Renault|               Golf|               car|               2012|\n",
      "|          false|                  1697|                966|            P13DT11H9M8S|                  1866|            2018-12-3T20:45:3...|           Hyundai|               Golf|               car|               2017|\n",
      "|          false|                  3004|                170|            P13DT11H9M8S|                  3004|            2018-12-3T20:45:3...|            Lancia|               Golf|               car|               2017|\n",
      "|          false|                  3981|                701|            P13DT11H9M8S|                  3981|            2018-12-3T20:45:3...|              Ford|               Golf|               car|               2006|\n",
      "|          false|                  3193|                261|            P13DT11H9M8S|                  3193|            2018-12-3T20:45:3...|              Ford|               Golf|               car|               2012|\n",
      "|          false|                  1831|                567|            P13DT11H9M8S|                  1831|            2018-12-3T20:45:3...|           Renault|               Golf|               car|               2014|\n",
      "|          false|                   109|                212|            P13DT11H9M8S|                   109|            2018-12-3T20:45:3...|              Ford|               Golf|               car|               2001|\n",
      "|          false|                  1588|                140|            P13DT11H9M8S|                  1746|            2018-12-3T20:45:3...|              Seat|               Golf|               car|               2005|\n",
      "|          false|                  2317|                505|            P13DT11H9M8S|                  2548|            2018-12-3T20:45:3...|              Ford|               Golf|               car|               2011|\n",
      "|          false|                  3560|                339|            P13DT11H9M8S|                  3916|            2018-12-3T20:45:3...|             Skoda|               Golf|               car|               2007|\n",
      "|          false|                   341|                495|            P13DT11H9M8S|                   341|            2018-12-3T20:45:3...|            Holden|               Golf|               car|               2003|\n",
      "|          false|                   482|                 99|            P13DT11H9M8S|                   482|            2018-12-3T20:45:3...|             Honda|               Golf|               car|               2007|\n",
      "|          false|                  3567|                 25|            P13DT11H9M8S|                  3567|            2018-12-3T20:45:3...|            Suzuki|               Golf|               car|               2013|\n",
      "|          false|                  3859|                100|            P13DT11H9M8S|                  3859|            2018-12-3T20:45:3...|        Volkswagen|               Golf|               car|               2012|\n",
      "|          false|                    35|                599|            P13DT11H9M8S|                    35|            2018-12-3T20:45:3...|            Holden|               Golf|               car|               2016|\n",
      "|          false|                  1603|                246|            P13DT11H9M8S|                  1603|            2018-12-3T20:45:3...|              Ford|               Golf|               car|               2005|\n",
      "|          false|                  1122|                 39|            P13DT11H9M8S|                  1122|            2018-12-3T20:45:3...|              Seat|               Golf|               car|               2012|\n",
      "+---------------+----------------------+-------------------+------------------------+----------------------+--------------------------------+------------------+-------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- approved.string: string (nullable = true)\n",
      " |-- approvedAmount.integer: long (nullable = true)\n",
      " |-- creditScore.integer: long (nullable = true)\n",
      " |-- duration.dayTimeDuration: string (nullable = true)\n",
      " |-- estimateAmount.integer: long (nullable = true)\n",
      " |-- trackingPointOccurrenceTime.date: string (nullable = true)\n",
      " |-- vehicleMake.string: string (nullable = true)\n",
      " |-- vehicleModel.string: string (nullable = true)\n",
      " |-- vehicleType.string: string (nullable = true)\n",
      " |-- vehicleYear.integer: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "businessdata = spark.sql(\"SELECT trackedFields.* from timeseries\")\n",
    "businessdata.show()\n",
    "businessdata.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Apache® Spark machine-learning model\n",
    "\n",
    "There are many types of machine learning models with many fundamental differences making them suitable for different requirements. Our model for recommendation uses Spark ML and in particular the Random Forest Classifier algorithm. Learn now how to prepare data, create an Apache® Spark machine-learning pipeline, and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation of data\n",
    "\n",
    "The following code rename the columns to remove the type from it.<br>\n",
    "Then, the StringIndexer method transforms the 'approved' column, which is a column of type 'string' containing only 'true' or 'false' values, into a numeric column with '0' and '1' values so that the classifier can understand it.<br>\n",
    "\n",
    "The VectorAssembler class creates a new features column which contains the features from which to build the model.<br>\n",
    "The IndexToString method transforms the prediction/classification of the model, which will be '0' and '1' values, back into \"true\" or \"false\" strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessdata = businessdata.withColumnRenamed(\"approved.string\", \"approved\")\n",
    "businessdata = businessdata.withColumnRenamed(\"creditScore.integer\", \"creditScore\")\n",
    "businessdata = businessdata.withColumnRenamed(\"estimateAmount.integer\", \"estimateAmount\")\n",
    "businessdata = businessdata.withColumnRenamed(\"approvedAmount.integer\", \"approvedAmount\")\n",
    "\n",
    "features = [\"approvedAmount\", \"creditScore\", \"estimateAmount\"]\n",
    "approvalColumn = \"approved\"\n",
    "\n",
    "\n",
    "approvalIndexer = StringIndexer(inputCol='approved', outputCol=\"label\").fit(businessdata)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=approvalIndexer.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating and training the model\n",
    "The model is built from the RandomForestClassifier algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below the data is split into training data and test data and the prediction model is trained and then tested, finally the accuracy of the model is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.935484\n",
      "Test Error = 0.0645161\n"
     ]
    }
   ],
   "source": [
    "businessdata = businessdata[features+['approved']]\n",
    "splitted_data = businessdata.randomSplit([0.8, 0.20], 24)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "\n",
    "pipeline = Pipeline(stages=[approvalIndexer, assembler, rf, labelConverter])\n",
    "\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the ML model available as a REST service\n",
    "Now you need to export the resulting ML model wich stored as a PMML file. After the model is stored, an Openscoring engine running on Docker makes it available as a REST scoring endpoint. The REST endpoint is then used as the recommendation service called by a process in BAW, providing recommendation for a user performing the task. This closes the whole loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML model is now trained and tested. But it still does exist in memory. It must be exported as PMML file in XML following PMML standard. You can explore what is inside the PMML file on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Administrator\\\\ibm-bai-workshop-main\\\\labs\\\\ai\\\\notebooks\\\\insurance-recommendation.pmml'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelName = \"insurance-recommendation\"\n",
    "modelFileName = modelName + \".pmml\"\n",
    "\n",
    "from pyspark2pmml import PMMLBuilder\n",
    "pmmlBuilder = PMMLBuilder(sc, train_data, model).putOption(rf, \"compact\", True)\n",
    "pmmlBuilder.buildFile(modelFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deploy the exported file to an already running instance of Openscoring engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML model deployment response: <Response [200]>\n",
      "{\n",
      "  \"id\" : \"insurance-recommendation\",\n",
      "  \"miningFunction\" : \"classification\",\n",
      "  \"summary\" : \"Ensemble model\",\n",
      "  \"properties\" : {\n",
      "    \"created.timestamp\" : \"2020-11-08T20:16:30.705+0000\",\n",
      "    \"accessed.timestamp\" : null,\n",
      "    \"file.size\" : 64471,\n",
      "    \"file.md5sum\" : \"0f0b95508e7f57e62b61a2d7fa48797c\",\n",
      "    \"model.version\" : null\n",
      "  },\n",
      "  \"schema\" : {\n",
      "    \"inputFields\" : [ {\n",
      "      \"id\" : \"approvedAmount\",\n",
      "      \"dataType\" : \"integer\",\n",
      "      \"opType\" : \"continuous\"\n",
      "    }, {\n",
      "      \"id\" : \"creditScore\",\n",
      "      \"dataType\" : \"integer\",\n",
      "      \"opType\" : \"continuous\"\n",
      "    }, {\n",
      "      \"id\" : \"estimateAmount\",\n",
      "      \"dataType\" : \"integer\",\n",
      "      \"opType\" : \"continuous\"\n",
      "    } ],\n",
      "    \"targetFields\" : [ {\n",
      "      \"id\" : \"approved\",\n",
      "      \"dataType\" : \"string\",\n",
      "      \"opType\" : \"categorical\",\n",
      "      \"values\" : [ \"false\", \"true\" ]\n",
      "    } ],\n",
      "    \"outputFields\" : [ {\n",
      "      \"id\" : \"prediction\",\n",
      "      \"dataType\" : \"double\",\n",
      "      \"opType\" : \"continuous\"\n",
      "    }, {\n",
      "      \"id\" : \"probability(false)\",\n",
      "      \"dataType\" : \"double\",\n",
      "      \"opType\" : \"continuous\"\n",
      "    }, {\n",
      "      \"id\" : \"probability(true)\",\n",
      "      \"dataType\" : \"double\",\n",
      "      \"opType\" : \"continuous\"\n",
      "    } ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(modelFileName,'rb') as openscoringBody:\n",
    "  openscoringUrl = 'http://mini:8080/model/' + modelName\n",
    "  openscoringHeaders = {'Content-Type':'text/xml'}\n",
    "  response = requests.put(openscoringUrl, headers=openscoringHeaders, data=openscoringBody, verify=False)\n",
    "print(\"ML model deployment response: \" + str(response))\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the recommendation URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test the scoring URL with sample data to see how it works. The next step consists in using this URL from within the Workflow process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML model test response: <Response [200]>\n",
      "{\n",
      "  \"results\" : {\n",
      "    \"approved\" : \"true\",\n",
      "    \"prediction\" : 1.0,\n",
      "    \"probability(false)\" : 0.4123384302416559,\n",
      "    \"probability(true)\" : 0.587661569758344\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "openscoringHeaders = {'Content-Type':'application/json', 'Accept':'application/json'}\n",
    "openscoringBody = '{\"arguments\":{\"approvedAmount\":800,\"creditScore\":1200,\"estimateAmount\":600}}'\n",
    "response = requests.post(openscoringUrl, headers=openscoringHeaders, data=openscoringBody, verify=False)\n",
    "print(\"ML model test response: \" + str(response))\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now your machine learning model is trained, deployed and ready to be invoked as a REST service from the process to provide the right recommendation to the user dureing the task processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the recommendation REST endpoint from the Workflow process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To display a recommendation for a decision on a claim within the Workflow process itself, invoke the Recommendation service from a Workflow service. \n",
    "<br>\n",
    "If you go back to the installed process application, you can see a service flow called 'Invoke ML Service Flow'. This is the service that calls the recommendation REST endpoint.\n",
    "<br>\n",
    "![](https://raw.githubusercontent.com/radeksulc/ibm-bai-workshop/main/labs/ai/images/invocationscript.png)\n",
    "<br>\n",
    "The Workflow process displays recommendations from the Spark machine-learning model.\n",
    "\n",
    "<br>\n",
    "The result of the recommendation service is displayed in the process UI (the coach) after the service has been called. In the picture below, you see that the coach contains two different parts, one for the 'I recommend' and another one for 'I do not recommend', the visibility of each portion depends on the result of the recommendation service.\n",
    "\n",
    "![](https://raw.githubusercontent.com/radeksulc/ibm-bai-workshop/main/labs/ai/images/coach.png)\n",
    "\n",
    "The system is now ready to return recommendations about the insurance claim.\n",
    "\n",
    "![](https://raw.githubusercontent.com/radeksulc/ibm-bai-workshop/main/labs/ai/images/reco.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This notebook is designed to help you understand how to create a recommendation service for your Process running in IBM Business AUtomation Workflow with Machine Learning and Business Automation Insights. You are encouraged to discover details of the components and deployed artifacts to understand the technical background at deeper level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:\n",
    "- Emmanuel Tissandier, Senior Technical Staff Member and architect in the Business Automation team in the IBM France Lab\n",
    "- Radek Sulc, Software Engineer, Digital Business Automation, Technical Engagement Team IBM EMEA - updates in 2020, switch to locally running OpenScoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
